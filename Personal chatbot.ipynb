{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37426e5",
   "metadata": {},
   "source": [
    "<p> Creating a basic chatbot with Python and some machine learning can be accomplished by using natural language processing (NLP) libraries like NLTK, spaCy, or Transformers. A simple chatbot doesn’t require deep machine learning models; instead, it can be powered by rule-based responses or simple intent classification with NLP. Here’s a minimal implementation of a chatbot using Python with basic ML/NLP concepts.</p>\n",
    "\n",
    "<p>Let’s create a simple chatbot that:\n",
    "\n",
    "<ol><li>Recognizes a few basic intents (e.g., greetings, questions, goodbyes).\n",
    "<li>Uses text processing for understanding and matching intents.\n",
    "<p>Here's a step-by-step example of a basic chatbot implementation:</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc736b",
   "metadata": {},
   "source": [
    "### Step 1: Install required packages\n",
    "Make sure you have nltk installed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffeb9d",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15e6368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e81217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59726ae0",
   "metadata": {},
   "source": [
    "### Step 3: Define Sample Data and Responses\n",
    "We'll create a small dataset of intents and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a351bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for chatbot intents\n",
    "intents = {\n",
    "    \"greeting\": [\"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\"],\n",
    "    \"goodbye\": [\"bye\", \"goodbye\", \"see you later\", \"take care\"],\n",
    "    \"thanks\": [\"thanks\", \"thank you\", \"much appreciated\", \"grateful\"],\n",
    "    \"question\": [\"how are you\", \"what's up\", \"how's it going\"]\n",
    "}\n",
    "\n",
    "# Responses for each intent\n",
    "responses = {\n",
    "    \"greeting\": [\"Hello! How can I help you today?\", \"Hi there!\", \"Hey! What’s up?\"],\n",
    "    \"goodbye\": [\"Goodbye! Have a great day!\", \"See you later!\", \"Take care!\"],\n",
    "    \"thanks\": [\"You're welcome!\", \"No problem!\", \"Happy to help!\"],\n",
    "    \"question\": [\"I'm a bot here to assist you!\", \"All systems are operational.\", \"I'm here to help, ask me anything!\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d39b78",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess Data and Train the Model\n",
    "<ol> <li> Preprocess each intent’s text by tokenizing and lemmatizing.\n",
    "<li> Vectorize the text to make it suitable for ML.</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122dc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and prepare data\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Create dataset for training\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "for intent, examples in intents.items():\n",
    "    for example in examples:\n",
    "        training_sentences.append(preprocess(example))\n",
    "        training_labels.append(intent)\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(training_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae8f24",
   "metadata": {},
   "source": [
    "### Step 5: Train a Simple Model\n",
    "We’ll use a basic Naive Bayes classifier for intent recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab6c3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727233e",
   "metadata": {},
   "source": [
    "### Step 6: Create a Function to Predict Intent and Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5018d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(user_input):\n",
    "    processed = preprocess(user_input)\n",
    "    X_input = vectorizer.transform([processed])\n",
    "    intent = clf.predict(X_input)[0]\n",
    "    return intent\n",
    "\n",
    "def get_response(user_input):\n",
    "    intent = get_intent(user_input)\n",
    "    return random.choice(responses[intent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9dd83",
   "metadata": {},
   "source": [
    "### Step 7: Create a Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30340d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm your chatbot. Press 'Esc' to end the conversation or type 'quit'.\n",
      "\n",
      "Bot: Goodbye!\n",
      "You: quit\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Flag to indicate when to exit\n",
    "exit_program = False\n",
    "\n",
    "def listen_for_esc():\n",
    "    global exit_program\n",
    "    while not exit_program:\n",
    "        # Detect Esc key\n",
    "        if keyboard.is_pressed('esc'):\n",
    "            exit_program = True\n",
    "            print(\"\\nBot: Goodbye!\")\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Start the thread\n",
    "esc_listener_thread = threading.Thread(target=listen_for_esc)\n",
    "esc_listener_thread.start()\n",
    "\n",
    "print(\"Hello! I'm your chatbot. Press 'Esc' to end the conversation or type 'quit'.\")\n",
    "\n",
    "while not exit_program:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"quit\" or exit_program:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Dummy response function; replace with actual function\n",
    "    response = f\"Echo: {user_input}\"\n",
    "    print(\"Bot:\", response)\n",
    "\n",
    "# Wait for the thread to finish if it’s still running\n",
    "esc_listener_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68751db",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "<p> Intents: A set of predefined phrases mapped to basic intents like greetings, thanks, and questions.\n",
    "<ol> <li>Preprocessing: Text is tokenized and lemmatized to improve recognition.\n",
    "<li>Vectorization: The input text is converted into a bag-of-words model.\n",
    "<li>Classification: A Naive Bayes classifier is trained to match phrases to intents.</ol>\n",
    "<p>Response Selection: Based on the predicted intent, a random response from the appropriate list is chosen.</p>\n",
    "\n",
    "### Run the Bot\n",
    "Run the code, and you’ll have a basic chatbot capable of recognizing and responding to a limited set of phrases. You can expand its vocabulary and intents to make it more interactive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225db77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
